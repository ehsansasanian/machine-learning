{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ea3c26",
   "metadata": {},
   "source": [
    "# Assignment 2: Training the Fully Recurrent Network\n",
    "\n",
    "*Author:* Thomas Adler\n",
    "\n",
    "*Copyright statement:* This  material,  no  matter  whether  in  printed  or  electronic  form,  may  be  used  for  personal  and non-commercial educational use only.  Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors.\n",
    "\n",
    "\n",
    "## Exercise 1: Data generation\n",
    "\n",
    "There are two classes, both occurring with probability 0.5. There is one input unit. Only the first sequence element conveys relevant information about the class. Sequence elements at positions $t > 1$ stem from a Gaussian with mean zero and variance 0.2. The first sequence element is 1.0 (-1.0) for class 1 (2). Target at sequence end is 1.0 (0.0) for class 1 (2)\n",
    "\n",
    "Write a function `generate_data` that takes an integer `T` as argument which represents the sequence length. Seed the `numpy` random generator with the number `0xDEADBEEF`. Implement the [Python3 generator](https://docs.python.org/3/glossary.html#term-generator) pattern and produce data in the way described above. The input sequences should have the shape `(T, 1)` and the target values should have the shape `(1,)`."
   ]
  },
  {
   "cell_type": "code",
   "id": "04244bb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T17:55:31.132408Z",
     "start_time": "2024-11-17T17:55:30.514142Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FullyRecurrentNetwork(object):\n",
    "    def __init__(self, D, I, K):\n",
    "        self.W = np.random.uniform(-0.01, 0.01, (I, D))\n",
    "        self.R = np.random.uniform(-0.01, 0.01, (I, I))\n",
    "        self.V = np.random.uniform(-0.01, 0.01, (K, I))\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        # helper function for numerically stable loss\n",
    "        def f(z):\n",
    "            return np.log1p(np.exp(-np.absolute(z))) + np.maximum(0, z)\n",
    "        \n",
    "        # infer dims\n",
    "        T, D = x.shape\n",
    "        K, I = self.V.shape\n",
    "\n",
    "        # init result arrays\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.a = np.zeros((T, I))\n",
    "\n",
    "        # iterate forward in time \n",
    "        # trick: access model.a[-1] in first iteration\n",
    "        for t in range(T):\n",
    "            self.a[t] = np.tanh(self.W @ x[t] + self.R @ self.a[t-1])\n",
    "            \n",
    "        self.z = model.V @ self.a[t]\n",
    "        return y * f(-self.z) + (1-y) * f(self.z)\n",
    "\n",
    "T, D, I, K = 10, 3, 5, 1\n",
    "model = FullyRecurrentNetwork(D, I, K)\n",
    "model.forward(np.random.uniform(-1, 1, (T, D)), 1)\n",
    "\n",
    "def generate_data(T):\n",
    "    \n",
    "    np.random.seed(0xDEADBEEF)\n",
    "\n",
    "    while True:\n",
    "        # Randomly assign class (0.5 probability for each)\n",
    "        class_label = np.random.choice([1, 2])\n",
    "\n",
    "        sequence = np.zeros((T, 1))\n",
    "\n",
    "        if class_label == 1:\n",
    "            sequence[0, 0] = 1.0\n",
    "            target = np.array([1.0])\n",
    "        else:\n",
    "            sequence[0, 0] = -1.0\n",
    "            target = np.array([0.0])\n",
    "\n",
    "        # Subsequent elements are Gaussian noise\n",
    "        sequence[1:, 0] = np.random.normal(loc=0.0, scale=np.sqrt(0.2), size=T-1)\n",
    "\n",
    "        yield sequence, target\n",
    "        \n",
    "data = generate_data(2)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "a9826f26",
   "metadata": {},
   "source": [
    "## Exercise 2: Gradients for the network parameters\n",
    "Compute gradients of the total loss \n",
    "$$\n",
    "L = \\sum_{t=1}^T L(t), \\quad \\text{where} \\quad L(t) = L(z(t), y(t))\n",
    "$$\n",
    "w.r.t. the weights of the fully recurrent network. To this end, find the derivative of the loss w.r.t. the logits and hidden pre-activations first, i.e., \n",
    "$$\n",
    "\\psi^\\top(t) = \\frac{\\partial L}{\\partial z(t)} \\quad \\text{and} \\quad \\delta^\\top(t) = \\frac{\\partial L}{\\partial s(t)}.\n",
    "$$\n",
    "With the help of these intermediate results you should be able to compute the gradients w.r.t. the weights, i.e., $\\nabla_W L, \\nabla_R L, \\nabla_V L$. \n",
    "\n",
    "*Hint: Take a look at the computational graph from the previous assignment to see the functional dependencies.*\n",
    "\n",
    "*Remark: Although we only have one label at the end of the sequence, we consider the more general case of evaluating a loss at every time step in this exercise (many-to-many mapping).*\n",
    "\n",
    "\n",
    "# Solution\n",
    "\n",
    "\n",
    "1. Gradient with respect to logits $ z(t) $:\n",
    "$$\n",
    "\\psi^\\top(t) = \\frac{\\partial L}{\\partial z(t)} = \\frac{\\partial L(t)}{\\partial z(t)}.\n",
    "$$\n",
    "\n",
    "2. Gradient with respect to hidden pre-activations $ s(t) $:\n",
    "Using the chain rule:\n",
    "$$\n",
    "\\delta^\\top(t) = \\frac{\\partial L}{\\partial s(t)} = \\psi^\\top(t) \\frac{\\partial z(t)}{\\partial s(t)} + \\delta^\\top(t+1) \\frac{\\partial h(t+1)}{\\partial s(t)}.\n",
    "$$\n",
    "3. \n",
    "$$\n",
    "    \\frac{\\partial z(t)}{\\partial s(t)} &= V^\\top \\phi'(s(t)), \n",
    "    \\frac{\\partial h(t+1)}{\\partial s(t)} &= R^\\top \\phi'(s(t)).\n",
    "$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$\n",
    "\\delta^\\top(t) = \\psi^\\top(t) V^\\top \\phi'(s(t)) + \\delta^\\top(t+1) R^\\top \\phi'(s(t)).\n",
    "1$$\n",
    "\n",
    "# Gradients with Respect to Weights\n",
    "\n",
    "1. Gradient with respect to $ W $:\n",
    "$$\n",
    "\\nabla_W L = \\sum_{t=1}^T \\frac{\\partial L}{\\partial s(t)} \\frac{\\partial s(t)}{\\partial W}.\n",
    "$$\n",
    "Since $ \\frac{\\partial s(t)}{\\partial W} = x(t)^\\top $, we have:\n",
    "$$\n",
    "\\nabla_W L = \\sum_{t=1}^T \\delta(t) x(t)^\\top.\n",
    "$$\n",
    "\n",
    "2. Gradient with respect to $ R $:\n",
    "$$\n",
    "\\nabla_R L = \\sum_{t=1}^T \\frac{\\partial L}{\\partial s(t)} \\frac{\\partial s(t)}{\\partial R}.\n",
    "$$\n",
    "Since $ \\frac{\\partial s(t)}{\\partial R} = h(t-1)^\\top $, we have:\n",
    "$$\n",
    "\\nabla_R L = \\sum_{t=1}^T \\delta(t) h(t-1)^\\top.\n",
    "$$\n",
    "\n",
    "\\paragraph{3. Gradient with respect to $ V $:}\n",
    "$$\n",
    "\\nabla_V L = \\sum_{t=1}^T \\frac{\\partial L}{\\partial z(t)} \\frac{\\partial z(t)}{\\partial V}.\n",
    "$$\n",
    "Since $ \\frac{\\partial z(t)}{\\partial V} = h(t)^\\top $, we have:\n",
    "$$\n",
    "\\nabla_V L = \\sum_{t=1}^T \\psi(t) h(t)^\\top.\n",
    "$$\n",
    "\n",
    "# Backpropagation Through Time (BPTT)\n",
    "\n",
    "The computation of $ \\delta(t) $ involves contributions from $ \\delta(t+1) $. This is handled iteratively:\n",
    "\\begin{itemize}\n",
    "    \\item Start at $ t = T $ with:\n",
    "    $$\n",
    "    \\delta(T) = \\psi^\\top(T) V^\\top \\phi'(s(T)).\n",
    "    $$\n",
    "    \\item Propagate backward to compute $ \\delta(t) $ for $ t = T-1, T-2, \\dots, 1 $.\n",
    "\\end{itemize}\n",
    "\n",
    "# Final Results\n",
    "\n",
    "The gradients are:\n",
    "$$\n",
    "\\nabla_W L = \\sum_{t=1}^T \\delta(t) x(t)^\\top,\n",
    "$$\n",
    "$$\n",
    "\\nabla_R L = \\sum_{t=1}^T \\delta(t) h(t-1)^\\top,\n",
    "$$\n",
    "$$\n",
    "\\nabla_V L = \\sum_{t=1}^T \\psi(t) h(t)^\\top,\n",
    "$$\n",
    "where $ \\psi(t) $ and $ \\delta(t) $ are computed recursively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21968f2c",
   "metadata": {},
   "source": [
    "## Exercise 3: The backward pass\n",
    "Write a function `backward` that takes a model `self` as argument. The function should compute the gradients of the loss with respect to all model parameters and store them to `self.dW`, `self.dR`, `self.dV`, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "id": "42e3d13c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T17:58:18.168305Z",
     "start_time": "2024-11-17T17:58:18.163704Z"
    }
   },
   "source": [
    "def backward(self):\n",
    "    # helper function for gradient of the loss\n",
    "    def df(z):\n",
    "        return -1 / (1 + np.exp(np.absolute(z)))\n",
    "\n",
    "        # get dimensions\n",
    "    T, D = self.x.shape\n",
    "    K, I = self.V.shape\n",
    "\n",
    "    # initialize gradient matrices\n",
    "    self.dW = np.zeros_like(self.W)  # (I, D)\n",
    "    self.dR = np.zeros_like(self.R)  # (I, I)\n",
    "    self.dV = np.zeros_like(self.V)  # (K, I)\n",
    "\n",
    "    # compute gradient of loss with respect to final output\n",
    "    dz = self.y * df(-self.z) + (1-self.y) * df(self.z)  # (K,)\n",
    "\n",
    "    # gradient for V (output layer)\n",
    "    self.dV = np.outer(dz, self.a[-1])  # (K, I)\n",
    "\n",
    "    # initialize gradient of hidden state\n",
    "    da_next = np.zeros(I)  # (I,)\n",
    "\n",
    "    # backpropagate through time\n",
    "    for t in reversed(range(T)):\n",
    "        # current hidden state\n",
    "        a_t = self.a[t]  # (I,)\n",
    "\n",
    "        # if it's the last timestep, add gradient from output\n",
    "        if t == T-1:\n",
    "            da = self.V.T @ dz  # (I,)\n",
    "        else:\n",
    "            da = np.zeros(I)  # (I,)\n",
    "\n",
    "        # add gradient from next timestep\n",
    "        da += da_next  # (I,)\n",
    "\n",
    "        # gradient through tanh\n",
    "        dtanh = (1 - a_t**2) * da  # (I,)\n",
    "\n",
    "        # gradients for W and R\n",
    "        self.dW += np.outer(dtanh, self.x[t])  # (I, D)\n",
    "        self.dR += np.outer(dtanh, self.a[t-1])  # (I, I)\n",
    "\n",
    "        # gradient for next timestep\n",
    "        da_next = self.R.T @ dtanh  # (I,)\n",
    "    \n",
    "\n",
    "FullyRecurrentNetwork.backward = backward\n",
    "model.backward()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "d58181c6",
   "metadata": {},
   "source": [
    "## Exercise 4: Gradient checking\n",
    "Write a function `grad_check` that takes a model `self`, a float `eps` and another float `thresh` as arguments and computes the numerical gradients of the model parameters according to the approximation\n",
    "$$\n",
    "f'(x) \\approx \\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2 \\varepsilon}.\n",
    "$$\n",
    "If any of the analytical gradients are farther than `thresh` away from the numerical gradients the function should throw an error. "
   ]
  },
  {
   "cell_type": "code",
   "id": "227e8631",
   "metadata": {},
   "source": [
    "def grad_check(self, eps, thresh):\n",
    "    # Save original parameters\n",
    "    original_W = self.W.copy()\n",
    "    original_R = self.R.copy()\n",
    "    original_V = self.V.copy()\n",
    "\n",
    "    # Placeholder for numerical gradients\n",
    "    numerical_dW = np.zeros_like(self.W)\n",
    "    numerical_dR = np.zeros_like(self.R)\n",
    "    numerical_dV = np.zeros_like(self.V)\n",
    "\n",
    "    # Helper function to compute loss for a forward pass\n",
    "    def compute_loss():\n",
    "        return np.sum(self.forward(self.x, self.y))\n",
    "\n",
    "    # Compute numerical gradient for W\n",
    "    for i in range(self.W.shape[0]):\n",
    "        for j in range(self.W.shape[1]):\n",
    "            self.W[i, j] += eps\n",
    "            loss_plus = compute_loss()\n",
    "            self.W[i, j] -= 2 * eps\n",
    "            loss_minus = compute_loss()\n",
    "            self.W[i, j] += eps  # Reset\n",
    "            numerical_dW[i, j] = (loss_plus - loss_minus) / (2 * eps)\n",
    "\n",
    "    # Compute numerical gradient for R\n",
    "    for i in range(self.R.shape[0]):\n",
    "        for j in range(self.R.shape[1]):\n",
    "            self.R[i, j] += eps\n",
    "            loss_plus = compute_loss()\n",
    "            self.R[i, j] -= 2 * eps\n",
    "            loss_minus = compute_loss()\n",
    "            self.R[i, j] += eps  # Reset\n",
    "            numerical_dR[i, j] = (loss_plus - loss_minus) / (2 * eps)\n",
    "\n",
    "    # Compute numerical gradient for V\n",
    "    for i in range(self.V.shape[0]):\n",
    "        for j in range(self.V.shape[1]):\n",
    "            self.V[i, j] += eps\n",
    "            loss_plus = compute_loss()\n",
    "            self.V[i, j] -= 2 * eps\n",
    "            loss_minus = compute_loss()\n",
    "            self.V[i, j] += eps  # Reset\n",
    "            numerical_dV[i, j] = (loss_plus - loss_minus) / (2 * eps)\n",
    "\n",
    "    # Compute analytical gradients using backward\n",
    "    self.backward()\n",
    "\n",
    "    # Check W gradients\n",
    "    if not np.allclose(self.dW, numerical_dW, atol=thresh):\n",
    "        raise ValueError(f\"W gradient check failed: max difference = {np.max(np.abs(self.dW - numerical_dW))}\")\n",
    "\n",
    "    # Check R gradients\n",
    "    if not np.allclose(self.dR, numerical_dR, atol=thresh):\n",
    "        raise ValueError(f\"R gradient check failed: max difference = {np.max(np.abs(self.dR - numerical_dR))}\")\n",
    "\n",
    "    # Check V gradients\n",
    "    if not np.allclose(self.dV, numerical_dV, atol=thresh):\n",
    "        raise ValueError(f\"V gradient check failed: max difference = {np.max(np.abs(self.dV - numerical_dV))}\")\n",
    "\n",
    "    print(\"Gradient check passed!\")\n",
    "\n",
    "FullyRecurrentNetwork.grad_check = grad_check\n",
    "model.grad_check(1e-7, 1e-7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0a5cdc05",
   "metadata": {},
   "source": [
    "## Exercise 5: Parameter update\n",
    "\n",
    "Write a function `update` that takes a model `self` and a float argument `eta`, which represents the learning rate. The method should implement the gradient descent update rule $\\theta \\gets \\theta - \\eta \\nabla_{\\theta}L$ for all model parameters $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "id": "e93c02c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T18:04:37.495743Z",
     "start_time": "2024-11-17T18:04:37.493160Z"
    }
   },
   "source": [
    "def update(self, eta):\n",
    "    self.W -= eta * self.dW\n",
    "    self.R -= eta * self.dR\n",
    "    self.V -= eta * self.dV\n",
    "\n",
    "FullyRecurrentNetwork.update = update\n",
    "model.update(0.001)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "19801bb8",
   "metadata": {},
   "source": [
    "## Exercise 6: Network training\n",
    "\n",
    "Train the fully recurrent network with 32 hidden units. Start with input sequences of length one and tune the learning rate and the number of update steps. Then increase the sequence length by one and tune the hyperparameters again. What is the maximal sequence length for which the fully recurrent network can achieve a performance that is better than random? Visualize your results. "
   ]
  },
  {
   "cell_type": "code",
   "id": "6d9781ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T18:08:12.219430Z",
     "start_time": "2024-11-17T18:08:12.190782Z"
    }
   },
   "source": "########## YOUR SOLUTION HERE ##########",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 67\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# Train for each sequence length\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m seq_len \u001B[38;5;129;01min\u001B[39;00m seq_lengths:\n\u001B[0;32m---> 67\u001B[0m     losses, accuracies \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseq_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[43mseq_len\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mn_epochs\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m        \u001B[49m\u001B[43meta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m[\u001B[49m\u001B[43mseq_len\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meta\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     final_accuracies\u001B[38;5;241m.\u001B[39mappend(accuracies[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m     73\u001B[0m     learning_curves\u001B[38;5;241m.\u001B[39mappend(accuracies)\n",
      "Cell \u001B[0;32mIn[12], line 20\u001B[0m, in \u001B[0;36mtrain_and_evaluate\u001B[0;34m(seq_length, n_epochs, eta, hidden_units, n_samples)\u001B[0m\n\u001B[1;32m     17\u001B[0m accuracies \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtqdm\u001B[49m(\u001B[38;5;28mrange\u001B[39m(n_epochs), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining (seq_length=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mseq_length\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     21\u001B[0m     total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     22\u001B[0m     correct \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "e1b52057",
   "metadata": {},
   "source": [
    "## Exercise 7: The Vanishing Gradient Problem\n",
    "\n",
    "Analyze why the network is incapable of learning long-term dependencies. Show that $\\|\\frac{\\partial a(T)}{\\partial a(1)}\\|_2 \\leq \\|R\\|_2^{T-1}$ , where $\\|\\cdot\\|_2$ is the spectral norm, and discuss how that affects the propagation of error signals through the time dimension of the network. \n",
    "\n",
    "*Hint: Use the fact that the spectral norm is submultiplicative for square matrices, i.e. $\\|AB\\|_2 \\leq \\|A\\|_2\\|B\\|_2$ if $A$ and $B$ are both square.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158130a5",
   "metadata": {},
   "source": [
    "########## YOUR SOLUTION HERE ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e50719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
